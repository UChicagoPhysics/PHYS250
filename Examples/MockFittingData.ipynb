{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical and systematic uncertainties in fitting\n",
    "\n",
    "Originally developed by William Irvine for PHYS 211 (January 2016)\n",
    "\n",
    "## Introduction \n",
    "\n",
    "This program generates mock data sets given a model, with adjustable statistical and systematic uncertainties.\n",
    "\n",
    "The purpose is to both quantitiatively and graphically represent the effects of statistical and systematic uncertainties on a linear fit to data. This is accomplished by generating a pseudodata dataset that is assigned both statistical and systematic uncertainties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "Import the appropriate libraries and define a several helper methods, such as creating linear functions, pseudodata, and figures.\n",
    "\n",
    "* `linear(p, x)`\n",
    "* `linear_residual(p, x, y, dy)`\n",
    "* `gauss(x, mu, sigma, A)`\n",
    "* `gdist(N=100, mean=0, sigma=5)`\n",
    "* `mockdata(x, sigma, func)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import loadtxt, optimize\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple linear function\n",
    "\n",
    "This function will create a line given is parameters (slope and y-intercept) and an array of values `x` at which to evaluate the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple linear function\n",
    "def linear(p, x):\n",
    "    \"\"\"\n",
    "    Creates a simple linear function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p: array of parameters\n",
    "      p[0] is the y-intercept\n",
    "      p[1] is the slope\n",
    "    \n",
    "    x: array of x-values at which to \n",
    "       evaluate the linear function\n",
    "    \"\"\"\n",
    "    \n",
    "    return p[0] + p[1]*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual linear function\n",
    "\n",
    "Computes the residuals for a simple linear function. Residuals are the differences between what is plotted in your scatter plot at a specific point, and what the linear equation predicts \"should be plotted\" at this specific point. That is, it's the difference between the \"observed\" and the \"expected\" values of a function evaluated at specific position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual of a linear function \n",
    "def linear_residual(p, x, y, dy):\n",
    "    \"\"\"\n",
    "    Computes the residuals for a simple linear function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p: array of parameters\n",
    "      p[0] is the y-intercept\n",
    "      p[1] is the slope\n",
    "    \n",
    "    x: array of x-values at which to \n",
    "       evaluate the linear function\n",
    "       \n",
    "    y: array of observed y-values\n",
    "    \n",
    "    dy: uncertainties on the observed y-values\n",
    "    \"\"\"\n",
    "    \n",
    "    return (linear(p,x)-y)/dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Gaussian function\n",
    "\n",
    "Nothing special here, just to explicitly create a Gaussian for display purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian function\n",
    "def gauss(x, mu, sigma, A):\n",
    "    return A*np.exp(-(x-mu)**2/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian random variable\n",
    "\n",
    "Here we want to draw values from a Gaussian distributions. I used the `numpy.random.randn(d0, d1, ..., dn)` function:\n",
    "\n",
    ">Return a sample (or samples) from the “standard normal” distribution. If positive, int_like or int-convertible arguments are provided, `randn` generates an array of shape `(d0, d1, ..., dn)`, filled with random floats sampled from a univariate “normal” (Gaussian) distribution of mean 0 and variance 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values drawn from gaussian distribution\n",
    "def gdist(N=100, mean=0, sigma=5):\n",
    "    return sigma*np.random.randn(N)+mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate `pseudodata`\n",
    "\n",
    "Here we want to draw values from a Gaussian distribution centered on some value with some standard deviation.\n",
    "\n",
    "The point is that we want to simulate the fact that our measurements of physical processes are statistical in nature, and so even if there is a \"true\" value, even a perfect measurement will really represent a sampling of an underlying distribution of possible measurements with some uncertainty. \n",
    "\n",
    "The `sigma` of this Gaussian will determine the uncertainties on the points we \"measure\" later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a mock dataset: function func evaluated at x-values x, with standard deviations sigma \n",
    "def mockdata(x, sigma, func):\n",
    "    \"\"\"\n",
    "    Generates a pseudodata dataset of y-values distributed according \n",
    "    to a Gaussian distribution, with a mean value given by evaluating \n",
    "    the function `func` at the corresponding x-values, `x`, and with\n",
    "    standard deviations `sigma`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: array of x-values at which to \n",
    "       evaluate the function provided\n",
    "      \n",
    "    sigma: value or array of values of \n",
    "           uncertainties on y-values at \n",
    "           each x-value specified\n",
    "       \n",
    "    func: function that gives the y-value \n",
    "          on which to center a Gaussian \n",
    "          distribution of possible y-values\n",
    "    \"\"\"\n",
    "    \n",
    "    # if standard deviation is a single number - that is assigned to all points\n",
    "    if np.size(sigma)==1:\n",
    "        sigma = sigma*np.ones_like(x)\n",
    "    \n",
    "    # Initialize an array to hold the generated distribution of y-values \n",
    "    # based on a probability distribution function func\n",
    "    yy=[]\n",
    "    \n",
    "    # otherwise each point can have a separate sigma\n",
    "    err=sigma\n",
    "    \n",
    "    # loop over all of the x-values and generate a Gaussian distribution \n",
    "    # of y-values given by the `gdist` function with standard deviations\n",
    "    # given by the uncertainty in the y-values specified by `sigma`\n",
    "    for xi, si in zip(x,sigma):\n",
    "        yy.append( gdist(N=1, mean=func(xi), sigma=si)[0] )\n",
    "    \n",
    "    yy = np.array(yy)\n",
    "    \n",
    "    # Return the array of y-values distributed according to a Gaussian \n",
    "    # distribution, with a mean value given by evaluating the function\n",
    "    # `func` at the corresponding x-values\n",
    "    return yy, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup variables and parameters\n",
    "\n",
    "Here is where we will set some variables and parameters for running our test data.\n",
    "\n",
    "In particular, we will set:\n",
    "* systematic uncertainties that (might) exist\n",
    "* \"true\" errors on our underlying model\n",
    "* estimated errors\n",
    "* slope and `y`-intercept of our \"true\" model (i.e. the model parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `x` values\n",
    "\n",
    "I just separate this out in order to have a clear and single place where the `x` values at which we will evaluate our function are defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x coordinates that specify the measurements\n",
    "xvalues = np.array([0,2,3,4,5,15,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systematic uncertainties\n",
    "\n",
    "Define any systematic uncertainties here. We will use these to update our \"measurements\" later. For a first iteration, you can set the values to zero using a multplier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systematic uncertainties for each measurement point\n",
    "systs = 0.0*np.array([1,3,-2,7,-3,2,-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"True\" errors\n",
    "\n",
    "Set the \"true\" statistical uncertainties that define the underlying distributions from which our measurements are drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underlying (\"true\") standard deviations of values of the measurements at each point `x`\n",
    "# These are what we will use to generate the distributions of possible measurements\n",
    "true_error = np.array([2,2,2,3,3,3,3.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Estimated\" errors\n",
    "\n",
    "These errors define the our estimates of the true errors. You can set them equal to one another, or not! Change this and see what happens to your distribution of chi-squared values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated errors (could be the same as the true errors, or not)\n",
    "estimated_error = 1.0*true_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True model\n",
    "\n",
    "These are the parameters of the \"true\" model (i.e. the slope and y-intercept of the line). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the \"true\" model. That is, we define the y-intercept (p0[0]) and slope (p0[1]) of our linear system \n",
    "p0 = [2,3.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating mock data\n",
    "\n",
    "We will use this for building our lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lambda function for handing to the mockdata\n",
    "func = lambda x: linear(p0, x)\n",
    "func_residual = linear_residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting helpers\n",
    "\n",
    "These are just a few functions that will help us with plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot true model (our line)\n",
    "\n",
    "Here we build a function that will plot the true model, i.e. our line. \n",
    "\n",
    "Having this in a single function will help us significantly later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plottruemodel(xarray, ax):\n",
    "    # plot the perfect line\n",
    "    ax.plot(xarray, func(xarray), '-', color='gray', alpha=0.3, label = 'True model')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make my figure\n",
    "\n",
    "This function just builds the figure and axes of our plots. This is useful because we are going to make several different plots and I want them all to look the same ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and its axes that we'll use throughout the plotting\n",
    "def make_my_figure(xmax=35, ymax=120): \n",
    "    \n",
    "    fig = plt.figure()\n",
    "\n",
    "    fig.patch.set_facecolor('w')\n",
    "\n",
    "    ax = fig.add_axes([0.15, 0.15, 0.75, 0.75]) \n",
    "    ax.set_title('Some Sample Data with Error Bars')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_xlim([0,xmax])\n",
    "    ax.set_ylim([0,ymax])\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `X` array\n",
    "\n",
    "This gives us an array of x-values to plot the line. We will use this throughout the examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives us an array of x-values to plot the line\n",
    "xarray = np.arange(0,35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run our toy simulation of \"nature\" (i.e. a straight line)\n",
    "\n",
    "Now we need to get to work! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axes so that they can be reused\n",
    "fig, ax = make_my_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build the canvas for drawing\n",
    "* Plot the true model (i.e. a perfect line given the model parameters)\n",
    "* Plot the PDFs of the underlying data, which represent the distribution of which our measurements will sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the canvas again\n",
    "fig, ax = make_my_figure()\n",
    "\n",
    "# plot the perfect line\n",
    "ax = plottruemodel(xarray, ax)\n",
    "\n",
    "# Annotate the plot to indicate what it is that we've drawn\n",
    "ax.annotate('physical law (y=%.1f + %.1f*x)' % (p0[0], p0[1]), \n",
    "            xy=(12, func(12)), xytext=(18, 38), \n",
    "            arrowprops=dict(facecolor='gray', shrink=0.11))\n",
    "\n",
    "ax.annotate('distributions from which measurements are drawn', \n",
    "            xy=(8, func(8)+4), xytext=(1, 100), \n",
    "            arrowprops=dict(facecolor='gray', shrink=0.11))\n",
    "\n",
    "# plot the pdfs of the underlying data\n",
    "for xi,tei in zip(xvalues, true_error):\n",
    "    yi = func(xi)\n",
    "    yyy = np.arange(yi-5*tei,yi+5*tei,10*tei/100.)\n",
    "    newxarray = xi+gauss(yyy,yi,tei,1)\n",
    "    ax.plot(newxarray,yyy,'-',color='gray',alpha=0.3)\n",
    "    ax.plot(xi,yi,'o',color='gray',alpha=0.3, label = '')\n",
    "\n",
    "    \n",
    "# Position the legend\n",
    "ax.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as above but\n",
    "* Add any systematic errors by shifting the underlying distributions away from the true model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the canvas again\n",
    "fig, ax = make_my_figure()\n",
    "\n",
    "# plot the true model\n",
    "ax = plottruemodel(xarray, ax)   \n",
    "\n",
    "# Annotate the plot\n",
    "ax.text(3,100,'add systematic errors to true distributions')\n",
    "\n",
    "# plot the pdfs of the underlying data\n",
    "for xi,tei,ssi in zip(xvalues, true_error, systs):\n",
    "    yo = func(xi)\n",
    "    yi = func(xi) + ssi\n",
    "    yyy = np.arange(yi-5*tei,yi+5*tei,10*tei/100.)\n",
    "    xxx = xi+gauss(yyy,yi,tei,1)\n",
    "    ax.plot(xxx,yyy,'-',color='gray',alpha=0.3)\n",
    "    ax.plot(xi,yi,'o',color='gray',alpha=0.3, label='')\n",
    "    ax.annotate('', xy=(xi,yi), xytext=(xi, yo), \n",
    "    arrowprops=dict(facecolor='green',arrowstyle=\"->\")) \n",
    "    \n",
    "\n",
    "# Position the legend\n",
    "ax.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as above but\n",
    "* Sample from the true underlying distributions by using the `mockdata` function\n",
    "* If there are systematic uncertainties, include them in the `yvalues_syst` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the canvas again\n",
    "fig, ax = make_my_figure()\n",
    "\n",
    "# plot the true model\n",
    "ax = plottruemodel(xarray, ax)   \n",
    "\n",
    "# Generate some pseudodata according to the true underlying PDF\n",
    "yvalues, ee     = mockdata(xvalues, true_error, func)\n",
    "yvalues_nominal = yvalues\n",
    "yvalues_syst    = yvalues + systs\n",
    "\n",
    "ax.text(3,100,'Make `measurements` by drawing\\n from true distribution')\n",
    "    \n",
    "# plot the pdfs of the underlying data\n",
    "for xi,tei,ssi in zip(xvalues, true_error, systs):\n",
    "    yo = func(xi)\n",
    "    yi = func(xi) + ssi\n",
    "    yyy = np.arange(yi-5*tei,yi+5*tei,10*tei/100.)\n",
    "    xxx = xi+gauss(yyy,yi,tei,1)\n",
    "    ax.plot(xxx,yyy,'-',color='gray',alpha=0.3)\n",
    "    ax.plot(xi,yi,'o',color='gray',alpha=0.3, label='')\n",
    "\n",
    "l2 = ax.plot(xvalues, yvalues_syst, 'ro', label = 'Measured Data')\n",
    "    \n",
    "# Position the legend\n",
    "ax.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now\n",
    "* add uncertainties to our measurements using the `sigma` from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the canvas again\n",
    "fig, ax = make_my_figure()\n",
    "\n",
    "# plot the true model\n",
    "ax = plottruemodel(xarray, ax)   \n",
    "\n",
    "# Generate some pseudodata according to the true underlying PDF\n",
    "yvalues, ee     = mockdata(xvalues, true_error, func)\n",
    "yvalues_nominal = yvalues\n",
    "yvalues_syst    = yvalues + systs\n",
    "\n",
    "ax.text(3,100,'Add uncertainties to our measurements\\n using the sigma from the model')\n",
    "    \n",
    "# plot the pdfs of the underlying data\n",
    "for xi,tei,ssi in zip(xvalues, true_error, systs):\n",
    "    yo = func(xi)\n",
    "    yi = func(xi) + ssi\n",
    "    yyy = np.arange(yi-5*tei,yi+5*tei,10*tei/100.)\n",
    "    xxx = xi+gauss(yyy,yi,tei,1)\n",
    "    ax.plot(xxx,yyy,'-',color='gray',alpha=0.3)\n",
    "    ax.plot(xi,yi,'o',color='gray',alpha=0.3)\n",
    "\n",
    "l2 = ax.errorbar(xvalues, yvalues_syst, ee, fmt='ro', label = 'Measured Data w/ stat errors')\n",
    " \n",
    "ax.legend(loc=4)    \n",
    "    \n",
    "#display.clear_output(wait=True)\n",
    "#display.display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform a fit to our measurements using the `optimize.leastsq` function\n",
    "   * See: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.leastsq.html\n",
    "   * Minimize the sum of squares of a set of equations\n",
    "   * `leastsq` is a wrapper around MINPACK’s `lmdif` and `lmder` algorithms.\n",
    "      * `cov_x` is a Jacobian approximation to the Hessian of the least squares objective function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the canvas again\n",
    "fig, ax = make_my_figure()\n",
    "\n",
    "# plot the true model\n",
    "ax = plottruemodel(xarray, ax)   \n",
    "\n",
    "# Generate some pseudodata according to the true underlying PDF\n",
    "yvalues, ee     = mockdata(xvalues, true_error, func)\n",
    "yvalues_nominal = yvalues\n",
    "yvalues_syst    = yvalues + systs\n",
    "\n",
    "ax.text(3, 110, 'Perform a fit to our measurements')\n",
    "\n",
    "# Perform the fit to our pseudodata\n",
    "fitparams, cov, info, mesg, success = optimize.leastsq(func_residual, p0, args=(xvalues, yvalues_syst, estimated_error), full_output=1)\n",
    "chisq = sum(info[\"fvec\"]*info[\"fvec\"])\n",
    "dof   = len(xvalues)-len(fitparams)\n",
    "\n",
    "# Put the fit errors \n",
    "fitparamerr = []\n",
    "for i in range(len(fitparams)):\n",
    "    fitparamerr.append(np.sqrt(cov[i,i]))\n",
    "\n",
    "# text for reporting fit paramaters\n",
    "textfit = '$f(x) = A + Bx$ \\n' \\\n",
    "          '$A = %.2f \\pm %.2f$ \\n' \\\n",
    "          '$B = %.2f \\pm %.2f$ \\n' \\\n",
    "          '$\\chi^2= %.1f$ \\n' \\\n",
    "          '$N = %i$ (dof) \\n' \\\n",
    "          '$\\chi^2/N = % .2f$' \\\n",
    "             % (fitparams[0], fitparamerr[0], fitparams[1], fitparamerr[1],\n",
    "                chisq, dof, chisq/dof)\n",
    "\n",
    "# plot the pdfs of the underlying data\n",
    "for xi,tei,ssi in zip(xvalues, true_error, systs):\n",
    "    yi = func(xi) + ssi\n",
    "    yyy = np.arange(yi-5*tei,yi+5*tei,10*tei/100.)\n",
    "    xxx = xi+gauss(yyy,yi,tei,1)\n",
    "    ax.plot(xxx,yyy,'-',color='gray',alpha=0.3)\n",
    "    ax.plot(xi,yi,'o',color='gray',alpha=0.3)\n",
    "\n",
    "\n",
    "#plot fitted line\n",
    "l3 = ax.plot(xvalues, linear(fitparams, xvalues), 'r-', label = 'Linear Fit')\n",
    "\n",
    "ax.annotate('fitted model', xy=(22, func(22)-7), xytext=(24, 40), \n",
    "        arrowprops=dict(facecolor='red', shrink=0.))\n",
    "\n",
    "ax.annotate('fit parameters', xy=(13,90), xytext=(18, 100), \n",
    "        arrowprops=dict(facecolor='red', shrink=0.))\n",
    "\n",
    "ax.text(0.05, .90, textfit, transform=ax.transAxes, fontsize=12, verticalalignment='top')\n",
    "\n",
    "# Now let's plot the data and the fit at the same time\n",
    "#l1 = ax.errorbar(xvalues, yy0, ee, fmt='ko', label = 'Unbiased Data',alpha=0.3)\n",
    "l2 = ax.errorbar(xvalues, yvalues_syst, estimated_error, fmt='ro', label = 'Measured Data')\n",
    "\n",
    "ax.legend(loc=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* Do the same as above, but many times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the canvas again\n",
    "fig, ax = make_my_figure()\n",
    "\n",
    "# initialize array for collecting results of fits\n",
    "results=[]\n",
    "\n",
    "# generate 200 different fits\n",
    "for rr in 1+np.arange(100):\n",
    "\n",
    "    plt.cla()\n",
    "    \n",
    "    # plot the true model\n",
    "    ax = plottruemodel(xarray, ax)   \n",
    "\n",
    "    # Generate some pseudodata according to the true underlying PDF\n",
    "    yvalues, ee     = mockdata(xvalues, true_error, func)\n",
    "    yvalues_nominal = yvalues\n",
    "    yvalues_syst    = yvalues + systs\n",
    "\n",
    "    # Perform the fit to our pseudodata\n",
    "    fitparams, cov, info, mesg, success = optimize.leastsq(func_residual, p0, args=(xvalues, yvalues_syst, estimated_error), full_output=1)\n",
    "    chisq = sum(info[\"fvec\"]*info[\"fvec\"])\n",
    "    dof   = len(xvalues)-len(fitparams)\n",
    "\n",
    "    # Put the fit errors \n",
    "    fitparamerr = []\n",
    "    for i in range(len(fitparams)):\n",
    "        fitparamerr.append(np.sqrt(cov[i,i]))\n",
    "\n",
    "    # text for reporting fit paramaters\n",
    "    textfit = '$f(x) = A + Bx$ \\n' \\\n",
    "              '$A = %.2f \\pm %.2f$ \\n' \\\n",
    "              '$B = %.2f \\pm %.2f$ \\n' \\\n",
    "              '$\\chi^2= %.1f$ \\n' \\\n",
    "              '$N = %i$ (dof) \\n' \\\n",
    "              '$\\chi^2/N = % .2f$' \\\n",
    "                 % (fitparams[0], fitparamerr[0], fitparams[1], fitparamerr[1],\n",
    "                    chisq, dof, chisq/dof)\n",
    "\n",
    "    # plot the pdfs of the underlying data\n",
    "    for xi,tei,ssi in zip(xvalues, true_error, systs):\n",
    "        yi = func(xi) + ssi\n",
    "        yyy = np.arange(yi-5*tei,yi+5*tei,10*tei/100.)\n",
    "        xxx = xi+gauss(yyy,yi,tei,1)\n",
    "        ax.plot(xxx,yyy,'-',color='gray',alpha=0.3)\n",
    "        ax.plot(xi,yi,'o',color='gray',alpha=0.3)\n",
    "\n",
    "    # Now let's plot the data and the fit at the same time\n",
    "    #l1 = ax.errorbar(xvalues, yy0, ee, fmt='ko', label = 'Unbiased Data',alpha=0.3)\n",
    "    l2 = ax.errorbar(xvalues, yvalues_syst, estimated_error, fmt='ro', label = 'Measured Data')\n",
    "\n",
    "\n",
    "    #plot fitted line\n",
    "    l3 = ax.plot(xvalues, linear(fitparams, xvalues), 'r-', label = 'Linear Fit')\n",
    "\n",
    "    #l4 = ax.errorbar(xx+0.1, yy, estimated_error, fmt='gx', label = 'Estimated Error')\n",
    "\n",
    "    ax.text(0.05, .90, textfit, transform=ax.transAxes, fontsize=12,verticalalignment='top')\n",
    "\n",
    "    #display.clear_output(wait=True)\n",
    "    #display.display(fig)\n",
    "\n",
    "    results.append([chisq/dof, fitparams[0], fitparams[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the canvas again\n",
    "fig, ax = make_my_figure(5,2)\n",
    "\n",
    "results = np.array(results)\n",
    "\n",
    "\n",
    "# Histogram the chi-square values\n",
    "ax.hist(results[:,0], bins=int(np.size(results[:,0])/2), alpha=0.2, density=True)\n",
    "\n",
    "ax.set_title('Spread of Reduced $\\chi^2$ values')\n",
    "ax.set_xlabel('Reduced $\\chi^2$')\n",
    "ax.set_ylabel('Relative frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the canvas again\n",
    "fig, ax = make_my_figure(5,2)\n",
    "\n",
    "# Histogram the chi-square values\n",
    "ax.hist(np.random.chisquare(dof,1000)/dof, bins=int(np.size(results[:,0])/30), alpha=0.2, density=True)\n",
    "\n",
    "ax.set_title('Distribution $\\chi^2$ values for Ndof = %d' % dof)\n",
    "ax.set_xlabel('Reduced $\\chi^2$')\n",
    "ax.set_ylabel('Relative frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the canvas again\n",
    "fig, ax = make_my_figure(10,2)\n",
    "\n",
    "# Histogram the y-intercepts\n",
    "ax.hist(results[:,1], bins=int(np.size(results[:,0])/2), alpha=0.2, density=True)\n",
    "\n",
    "ax.plot([p0[0],p0[0]],[0,1],'-r')\n",
    "\n",
    "ax.set_title('Spread of values for $A$')\n",
    "ax.set_xlabel('$A$')\n",
    "ax.set_ylabel('Relative frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the canvas again\n",
    "fig, ax = make_my_figure(10,6)\n",
    "\n",
    "# Histogram the slopes\n",
    "ax.hist(results[:,2], bins=int(np.size(results[:,0])/30), alpha=0.2, density=True)\n",
    "\n",
    "ax.plot([p0[1],p0[1]],[0,1],'-r')\n",
    "\n",
    "ax.set_title('Spread of values for $B$')\n",
    "ax.set_xlabel('$B$')\n",
    "ax.set_ylabel('Relative frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
